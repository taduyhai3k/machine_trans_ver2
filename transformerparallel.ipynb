{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9463807,"sourceType":"datasetVersion","datasetId":5754140},{"sourceId":9471947,"sourceType":"datasetVersion","datasetId":5760267},{"sourceId":120045,"sourceType":"modelInstanceVersion","modelInstanceId":100335,"modelId":124501},{"sourceId":121899,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":102567,"modelId":126790},{"sourceId":121901,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":102569,"modelId":126792}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!rm -rf /kaggel/working/*","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-05T09:04:36.814157Z","iopub.execute_input":"2024-10-05T09:04:36.814746Z","iopub.status.idle":"2024-10-05T09:04:37.849670Z","shell.execute_reply.started":"2024-10-05T09:04:36.814715Z","shell.execute_reply":"2024-10-05T09:04:37.848404Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/taduyhai3k/machine_trans_ver2","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:04:45.361478Z","iopub.execute_input":"2024-10-05T09:04:45.361830Z","iopub.status.idle":"2024-10-05T09:04:49.822945Z","shell.execute_reply.started":"2024-10-05T09:04:45.361801Z","shell.execute_reply":"2024-10-05T09:04:49.821761Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Cloning into 'machine_trans_ver2'...\nremote: Enumerating objects: 73, done.\u001b[K\nremote: Counting objects: 100% (73/73), done.\u001b[K\nremote: Compressing objects: 100% (53/53), done.\u001b[K\nremote: Total 73 (delta 18), reused 72 (delta 17), pack-reused 0 (from 0)\u001b[K\nUnpacking objects: 100% (73/73), 21.08 MiB | 8.59 MiB/s, done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os, sys\n# lấy ra đường dẫn đến thư mục modules ở trong projetc hiện hành\nlib_path = os.path.abspath(os.path.join('machine_trans_ver2'))\n# thêm thư mục cần load vào trong hệ thống\nsys.path.append(lib_path)\nimport argparse\nfrom machine_trans_ver2 import utils,  MyData, MyTrans","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:04:51.645804Z","iopub.execute_input":"2024-10-05T09:04:51.646718Z","iopub.status.idle":"2024-10-05T09:04:56.398722Z","shell.execute_reply.started":"2024-10-05T09:04:51.646679Z","shell.execute_reply":"2024-10-05T09:04:56.397749Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\na = torch.load(\"/kaggle/input/para/pytorch/default/1/bestmodel_parallel.pth\", map_location = 'cuda')\ntorch.save(a, \"machine_trans_ver2/checkpoint/bestmodel_parallel.pth\")\nb = pd.read_csv(\"/kaggle/input/d/hai3kk/metric-v2e/metric_V2E.csv\")\nb.to_csv(\"machine_trans_ver2/metric/metric_E2V.csv\")\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:05:02.238677Z","iopub.execute_input":"2024-10-05T09:05:02.239367Z","iopub.status.idle":"2024-10-05T09:05:04.241025Z","shell.execute_reply.started":"2024-10-05T09:05:02.239333Z","shell.execute_reply":"2024-10-05T09:05:04.240044Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import argparse \n\nparse = argparse.ArgumentParser(description=\"machine translation using transformer\")\nparse.add_argument(\"--path_train\", type=str, help=\"path to data train\", default='data/train1.json')\nparse.add_argument(\"--path_valid\", type=str, help=\"path to data valid\", default='data/valid1.json')\nparse.add_argument(\"--path_test\", type=str, help=\"path to data test\", default='data/test1.json')\nparse.add_argument(\"--in_lang\", type=str, help=\"input language\", default='E')\nparse.add_argument(\"--out_lang\", type=str, help=\"output language\", default='V')\nparse.add_argument(\"--vocab_E\", type=str, help=\"path Vocabulary of E\", default='vocab/vocabE1.json')\nparse.add_argument(\"--vocab_V\", type=str, help=\"path Vocabulary of V\", default='vocab/vocabV1.json')\nparse.add_argument(\"--dmodel\", type=int, help=\"Dimension of model\", default=128)\nparse.add_argument(\"--dembed\", type=int, help=\"Dimension of embedding\", default=128)\nparse.add_argument(\"--d_ff\", type=int, help=\"Dimension of feed-forward layer\", default=256)\nparse.add_argument(\"--head\", type=int, help=\"Number of attention heads\", default=8)\nparse.add_argument(\"--active\", type=str, help=\"Type of activation function\", default=\"relu\")\nparse.add_argument(\"--layer\", type=int, help=\"Number of layers\", default=2)\nparse.add_argument(\"--dropout\", type=float, help=\"Dropout rate\", default=0.1)\nparse.add_argument(\"--eps\", type=float, help=\"Epsilon value\", default=1e-5)\nparse.add_argument(\"--epoch\", type= int, default= 12, help= \"epoch\")\nparse.add_argument(\"--batch_size\", type= int, default= 128, help = \"batch size in training and testing\")\nparse.add_argument(\"--result_path\", type= str, default= \"checkpoint/bestmodel_E2V.pth\", help = \"file path to result model\")\nparse.add_argument(\"--metric_path\", type= str, default= \"metric/metric_V2E.csv\", help = \"file path to result metric\")\nparse.add_argument(\"--folder\", type = str, default = \"machine_trans_ver2\", help = \"folder have data, checkpoint, metric\")\nargs, unknown = parse.parse_known_args()\n\npath_train = os.path.join(args.folder, args.path_train)\npath_test = os.path.join(args.folder, args.path_test)\npath_valid = os.path.join(args.folder, args.path_valid)\nvocab_E = os.path.join(args.folder, args.vocab_E)\nvocab_V = os.path.join(args.folder, args.vocab_V)\nresult_path = os.path.join(args.folder, args.result_path)\nmetric_path = os.path.join(args.folder, args.metric_path)\ndata_train = MyData.EV_Data(path_train, inp = args.in_lang, out = args.out_lang, E_vocab_path= vocab_E, V_vocab_path= vocab_V)\nmodel = MyTrans.TransformerParallel(input_vocab_size= len(data_train.inp_vocab), output_vocab_size = len(data_train.out_vocab), dmodel = args.dmodel, dembed = args.dembed,\n                        d_ff= args.d_ff, head = args.head, active= args.active, layer= args.layer, dropout= args.dropout, eps = args.eps)\n# model = MyTrans.Transformer(input_vocab_size= len(data_train.inp_vocab), output_vocab_size = len(data_train.out_vocab), dmodel = args.dmodel, dembed = args.dembed,\n#                         d_ff= args.d_ff, head = args.head, active= args.active, layer= args.layer, dropout= args.dropout, eps = args.eps)\ndata_train = MyData.DataLoader(data_train, batch_size= args.batch_size, shuffle= False)\nif args.path_valid is not None:\n    data_valid = MyData.EV_Data(path_valid, inp = args.in_lang, out = args.out_lang, E_vocab_path= vocab_E, V_vocab_path= vocab_V)\n    data_valid = MyData.DataLoader(data_valid, batch_size= args.batch_size, shuffle= False)\n    data_test = MyData.EV_Data(path_test, inp = args.in_lang, out = args.out_lang, E_vocab_path= vocab_E, V_vocab_path= vocab_V)\n    data_test = MyData.DataLoader(data_test, batch_size= args.batch_size, shuffle= False)\nelse:\n    data_valid = None\n    data_test = None\n# optimizer = utils.optim.Adam(model.parameters(), lr = 1.0, betas= (0.9, 0.98), eps= 1e-9)     \n# utils.train(model, optimizer, args.epoch, data_train, data_valid, data_test,result_path, metric_path)\nmodel.load_state_dict(a['model'])\n    \n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:05:07.182977Z","iopub.execute_input":"2024-10-05T09:05:07.183593Z","iopub.status.idle":"2024-10-05T09:05:09.237392Z","shell.execute_reply.started":"2024-10-05T09:05:07.183560Z","shell.execute_reply":"2024-10-05T09:05:09.236487Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}]},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(total_params)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:05:12.768947Z","iopub.execute_input":"2024-10-05T09:05:12.769925Z","iopub.status.idle":"2024-10-05T09:05:12.775035Z","shell.execute_reply.started":"2024-10-05T09:05:12.769889Z","shell.execute_reply":"2024-10-05T09:05:12.774159Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"9650688\n","output_type":"stream"}]},{"cell_type":"code","source":"import json\nmodel.load_state_dict(a['model'])\nwith open(vocab_E, \"r\", encoding='utf-8') as file:\n    vocabE = json.load(file)  \nwith open(vocab_V, \"r\", encoding='utf-8') as file:\n    vocabV = json.load(file)  \n    \nE_tokenizer = MyData.MyTokenizer(vocabE)\nV_tokenizer = MyData.MyTokenizer(vocabV)      ","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:05:15.932041Z","iopub.execute_input":"2024-10-05T09:05:15.932756Z","iopub.status.idle":"2024-10-05T09:05:15.988344Z","shell.execute_reply.started":"2024-10-05T09:05:15.932728Z","shell.execute_reply":"2024-10-05T09:05:15.987524Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef predict(model, data, inp_tokennizer, out_tokenizer, max_lenth = 300):\n    #translate one sentences\n    inp_encode = data.reshape(1,-1).to('cuda')\n    out_encode = out_tokenizer.encode('<start>')[1].reshape(1, -1).to('cuda')\n    for i in range(max_lenth):\n        pred = model(inp_encode, out_encode)\n        preds = pred[:, -1, :].reshape(1, -1)\n        predict_id = torch.argmax(preds, dim = -1, keepdim= True).type(torch.int64)\n        out_encode = torch.cat([out_encode, predict_id], dim = -1)\n        if out_tokenizer.encode('<end>')[1] == predict_id:\n            return out_tokenizer.decode(out_encode.reshape(-1))\n    return out_tokenizer.decode(out_encode.reshape(-1))     \n\ndef predict_parallel(model, data, inp_tokennizer, out_tokenizer, inp = 'E',max_lenth = 300):\n    #translate one sentences\n    model.eval()\n    inp_encode = inp_tokennizer.encode(data).reshape(1, -1)\n    out_encode = out_tokenizer.encode('<start>')[1].reshape(1, -1)\n    with torch.no_grad():\n        for i in range(max_lenth):\n            pred = model(inp_encode, out_encode, inp)\n            preds = pred[:, -1, :].reshape(1, -1)\n            predict_id = torch.argmax(preds, dim = -1, keepdim= True).type(torch.int64)\n            out_encode = torch.cat([out_encode, predict_id], dim = -1)\n            if out_tokenizer.encode('<end>')[1] == predict_id:\n                return out_tokenizer.decode(out_encode.reshape(-1))\n    return out_tokenizer.decode(out_encode.reshape(-1))     \ncandidate = []\nreference = []\nmodel.eval()\ndatas = [data_train, data_test, data_valid]\nwith torch.no_grad():\n    for data in datas:\n        data = tqdm(data, desc='Process', position=0, leave=True) \n        for batch in data:\n            inp, target = batch[0].to('cuda'), batch[1].to('cuda')\n            tmp_can = model.inference(target, 16,'V',300)\n            candidate = candidate + tmp_can\n            reference = reference + inp.tolist()\n            \n            ","metadata":{"execution":{"iopub.status.busy":"2024-10-05T09:05:18.679429Z","iopub.execute_input":"2024-10-05T09:05:18.680251Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Process: 100%|██████████| 2630/2630 [45:13<00:00,  1.03s/it]\nProcess:  50%|████▉     | 104/209 [01:03<01:02,  1.67it/s]","output_type":"stream"}]},{"cell_type":"code","source":"length = 0\nfor i in range(len(candidate)):\n    length += len(candidate[i])\n\nprint(length * 1.0 /len(candidate) )    ","metadata":{"execution":{"iopub.status.busy":"2024-10-05T10:03:13.616669Z","iopub.execute_input":"2024-10-05T10:03:13.617401Z","iopub.status.idle":"2024-10-05T10:03:14.299150Z","shell.execute_reply.started":"2024-10-05T10:03:13.617365Z","shell.execute_reply":"2024-10-05T10:03:14.298213Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"13.937399024480312\n","output_type":"stream"}]},{"cell_type":"code","source":"a = '\",\"'.join(str(x) for x in reference[0])","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:17:04.462718Z","iopub.execute_input":"2024-10-04T16:17:04.463328Z","iopub.status.idle":"2024-10-04T16:17:04.467805Z","shell.execute_reply.started":"2024-10-04T16:17:04.463296Z","shell.execute_reply":"2024-10-04T16:17:04.466694Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"a","metadata":{"execution":{"iopub.status.busy":"2024-10-04T16:17:06.595274Z","iopub.execute_input":"2024-10-04T16:17:06.595644Z","iopub.status.idle":"2024-10-04T16:17:06.601380Z","shell.execute_reply.started":"2024-10-04T16:17:06.595614Z","shell.execute_reply":"2024-10-04T16:17:06.600407Z"},"trusted":true},"execution_count":38,"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"'1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0\",\"0'"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu\n\n# Tính chỉ số BLEU cho một cặp câu\ndef calculate_bleu(reference, candidate):\n    \"\"\"\n    Tính điểm BLEU giữa câu tham chiếu và câu dự đoán.\n    \n    :param reference: List chứa các câu tham chiếu, mỗi câu là một list các từ (tokens).\n                      VD: [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\", \"test\"]]\n    :param candidate: List chứa câu dự đoán (tokens).\n                      VD: [\"this\", \"is\", \"a\", \"test\"]\n    :return: Điểm BLEU.\n    \"\"\"\n    candidate = '\",\"'.join(str(x) for x in candidate.tolist())\n    reference = '\",\"'.join(str(x) for x in reference if x != 0) \n    bleu_score = sentence_bleu(reference, candidate)\n    return bleu_score\n\n# Ví dụ sử dụng\npoint = 0\nfor i in tqdm(range(len(candidate))):\n    point += calculate_bleu(reference[i], candidate[i])\nprint(f\"BLEU Score: {point / len(candidate)}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-05T10:03:22.986416Z","iopub.execute_input":"2024-10-05T10:03:22.987127Z","iopub.status.idle":"2024-10-05T10:57:23.685255Z","shell.execute_reply.started":"2024-10-05T10:03:22.987098Z","shell.execute_reply":"2024-10-05T10:57:23.684315Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"100%|██████████| 389946/389946 [54:00<00:00, 120.33it/s] ","output_type":"stream"},{"name":"stdout","text":"BLEU Score: 0.6504610979909451\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu\nfrom joblib import Parallel, delayed\n\n# Tính chỉ số BLEU cho một cặp câu\ndef calculate_bleu(reference, candidate):\n    \"\"\"\n    Tính điểm BLEU giữa câu tham chiếu và câu dự đoán.\n    \n    :param reference: List chứa các câu tham chiếu, mỗi câu là một list các từ (tokens).\n                      VD: [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\", \"test\"]]\n    :param candidate: List chứa câu dự đoán (tokens).\n                      VD: [\"this\", \"is\", \"a\", \"test\"]\n    :return: Điểm BLEU.\n    \"\"\"\n    candidate = '\",\"'.join(str(x) for x in candidate.tolist())\n    reference = '\",\"'.join(str(x) for x in reference if x != 0) \n    bleu_score = sentence_bleu(reference, candidate)\n    return bleu_score\n\n# Hàm xử lý song song trên nhiều cặp câu\ndef parallel_bleu(reference_list, candidate_list, n_jobs=-1):\n    \"\"\"\n    Tính BLEU song song cho nhiều cặp câu.\n    \n    :param reference_list: List các câu tham chiếu (tokens).\n    :param candidate_list: List các câu dự đoán (tokens).\n    :param n_jobs: Số lượng CPU core để sử dụng (mặc định là tất cả).\n    :return: List các điểm BLEU.\n    \"\"\"\n    bleu_scores = Parallel(n_jobs=n_jobs)(delayed(calculate_bleu)(ref, cand) for ref, cand in zip(reference_list, candidate_list))\n    return bleu_scores\n\na = parallel_bleu(reference, candidate)","metadata":{"execution":{"iopub.status.busy":"2024-10-05T08:47:49.320478Z","iopub.execute_input":"2024-10-05T08:47:49.320846Z","iopub.status.idle":"2024-10-05T08:49:50.715623Z","shell.execute_reply.started":"2024-10-05T08:47:49.320817Z","shell.execute_reply":"2024-10-05T08:49:50.714076Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n/opt/conda/lib/python3.10/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \nCorpus/Sentence contains 0 counts of 2-gram overlaps.\nBLEU scores might be undesirable; use SmoothingFunction().\n  warnings.warn(_msg)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[20], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     bleu_scores \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(calculate_bleu)(ref, cand) \u001b[38;5;28;01mfor\u001b[39;00m ref, cand \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(reference_list, candidate_list))\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bleu_scores\n\u001b[0;32m---> 34\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_bleu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[20], line 31\u001b[0m, in \u001b[0;36mparallel_bleu\u001b[0;34m(reference_list, candidate_list, n_jobs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_bleu\u001b[39m(reference_list, candidate_list, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124;03m    Tính BLEU song song cho nhiều cặp câu.\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    :return: List các điểm BLEU.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     bleu_scores \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_bleu\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcand\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreference_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bleu_scores\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'machine_translation_viet_eng/metric/metric_E2V.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-02T17:18:04.909668Z","iopub.execute_input":"2024-09-02T17:18:04.910456Z","iopub.status.idle":"2024-09-02T17:18:04.917072Z","shell.execute_reply.started":"2024-09-02T17:18:04.910425Z","shell.execute_reply":"2024-09-02T17:18:04.916311Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/machine_translation_viet_eng/metric/metric_E2V.csv","text/html":"<a href='machine_translation_viet_eng/metric/metric_E2V.csv' target='_blank'>machine_translation_viet_eng/metric/metric_E2V.csv</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\nbatch_size = 64\nvocab_E = os.path.join(\"machine_translation_viet_eng\",\"vocab/vocabE1.json\")\nvocab_V = os.path.join(\"machine_translation_viet_eng\", \"vocab/vocabV1.json\")\n\ndata_train = MyData.EV_Data(\"machine_translation_viet_eng/data/train1.json\", inp = \"E\", out = \"V\", E_vocab_path= vocab_E, V_vocab_path= vocab_V)\ndata_train = MyData.DataLoader(data_train, batch_size= batch_size, shuffle= False)\ndata_valid = MyData.EV_Data(\"machine_translation_viet_eng/data/valid1.json\", inp = \"E\", out = \"V\", E_vocab_path= vocab_E, V_vocab_path= vocab_V)\ndata_valid = MyData.DataLoader(data_valid, batch_size= batch_size, shuffle= False)\ndata_test = MyData.EV_Data(\"machine_translation_viet_eng/data/test1.json\", inp = \"E\", out = \"V\", E_vocab_path= vocab_E, V_vocab_path= vocab_V)\ndata_test = MyData.DataLoader(data_test, batch_size= batch_size, shuffle= False)\n\nd\nsmoothing_func = SmoothingFunction().method1\nbleu_score = sentence_bleu([reference], candidate, smoothing_function=smoothing_func)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a = (torch.gather(tmp.softmax(dim = -1)[:, :-1, :], dim = -1, index = y.unsqueeze(dim = -1)[:, 1:,:]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a[a< 1e-40] = 1e-40","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"utils.SparseCrossEntropy(y, tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{},"execution_count":null,"outputs":[]}]}